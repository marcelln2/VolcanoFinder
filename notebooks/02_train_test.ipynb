{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-17T13:09:22.253875Z",
     "start_time": "2025-10-17T13:09:19.807147Z"
    }
   },
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import kornia.augmentation as K\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from projects.VolcanoFinder.models import MyFirstCNN\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T13:09:22.348725Z",
     "start_time": "2025-10-17T13:09:22.261881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "To learn:\n",
    "- Look at feature maps (patterns)\n",
    "\"\"\"\n",
    "\n",
    "cpu_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder(root='C:/Users/spec/Documents/programming/projects/VolcanoFinder/data/train', transform=cpu_transforms)\n",
    "val_dataset = ImageFolder(root='C:/Users/spec/Documents/programming/projects/VolcanoFinder/data/val', transform=cpu_transforms)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=12,\n",
    "    prefetch_factor=6,\n",
    "    persistent_workers=True,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=12,\n",
    "    prefetch_factor=6,\n",
    "    persistent_workers=True,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "gpu_augmentations = nn.Sequential(\n",
    "    K.Resize((128, 128)),\n",
    "    K.RandomAffine(degrees=0, translate=(0.2, 0.2)),\n",
    "    K.Normalize(mean=torch.tensor([0.5, 0.5, 0.5], device=device),\n",
    "                std=torch.tensor([0.5, 0.5, 0.5], device=device))\n",
    ").to(device)\n",
    "\n",
    "# ------------------------------- #\n",
    "# Tried, but disadvantageous: RandRotation, RandGaussianNoise (Terrible, barely above 50% accuracy), ColorJitter, RandGauBlur, RandSolarize (- ~6%)\n",
    "# ------------------------------- #"
   ],
   "id": "82918d47816296de",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T13:09:46.466670Z",
     "start_time": "2025-10-17T13:09:22.357825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ------------------------------- #\n",
    "best_accuracy: float = 0.0\n",
    "results: list = []\n",
    "runs: int = 200\n",
    "\n",
    "for i in range(runs):\n",
    "    print(f\"===================== RUN: {i+1}/{runs} =====================\")\n",
    "    model = MyFirstCNN().to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "\n",
    "    scheduler =  torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "    # ------------TRAIN--------------- #\n",
    "    num_epochs: int = 20\n",
    "    best_val_loss: float = math.inf\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss: float = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.float().unsqueeze(1).to(device, non_blocking=True)\n",
    "\n",
    "            images = gpu_augmentations(images)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        #print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "        # ------------VALIDATE--------------- #\n",
    "        model.eval()\n",
    "        val_correct: int = 0\n",
    "        val_total: int = 0\n",
    "        val_loss: float = 0.0\n",
    "        with torch.inference_mode():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device, non_blocking=True)\n",
    "                labels = labels.float().unsqueeze(1).to(device, non_blocking=True)\n",
    "\n",
    "                outputs = model(images)\n",
    "                val_loss += criterion(outputs, labels.float()).item()\n",
    "\n",
    "                predicted = (outputs > 0.5).float()\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        avg_val_loss: float = val_loss / len(val_loader)\n",
    "        val_accuracy: float = 100 * val_correct / val_total\n",
    "\n",
    "        current_best_model_path = f'volcano_finder_myowncnn_run_{i+1}_best.pth'\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), current_best_model_path)\n",
    "            #print(f\" ------------- Best model saved | Epoch: {epoch + 1}, Val loss: {avg_val_loss:.4f} ------------- \")\n",
    "\n",
    "        #print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "    # ------------TEST--------------- #\n",
    "\n",
    "    test_data_path = 'C:/Users/spec/Documents/programming/projects/VolcanoFinder/data/test_images'\n",
    "    test_dataset = ImageFolder(root=test_data_path, transform=cpu_transforms)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    loaded_model = MyFirstCNN().to(device)\n",
    "\n",
    "    loaded_model.load_state_dict(torch.load(current_best_model_path))\n",
    "\n",
    "    loaded_model.to(device)\n",
    "    loaded_model.eval()\n",
    "\n",
    "\n",
    "    test_correct: int = 0\n",
    "    test_total: int = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "            outputs = loaded_model(images)\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy: float = 100 * test_correct / test_total\n",
    "    results.append(accuracy)\n",
    "    print('\\n# ------------------------------- #\\n')\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\\n\")\n",
    "\n",
    "    if (accuracy > best_accuracy):\n",
    "        best_accuracy = accuracy\n",
    "        print(f\"\\nNew best: {best_accuracy:.2f}%\\n\\n\")\n",
    "        torch.save(loaded_model.state_dict(), \"best_volcano_finder.pth\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    if os.path.exists(current_best_model_path):\n",
    "        os.remove(current_best_model_path)\n",
    "\n",
    "plt.plot(results)\n",
    "plt.xlabel('Runs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "print('Done!')\n",
    "print(f'\\n\\nBest accuracy: {best_accuracy:.2f}%\\n')\n",
    "print(sum(results)/len(results))\n",
    "# ------------------------------- #"
   ],
   "id": "77d858704746c80b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== RUN: 1/200 =====================\n",
      "\n",
      "# ------------------------------- #\n",
      "\n",
      "Test Accuracy: 73.22%\n",
      "\n",
      "\n",
      "New best: 73.22%\n",
      "\n",
      "\n",
      "===================== RUN: 2/200 =====================\n",
      "\n",
      "# ------------------------------- #\n",
      "\n",
      "Test Accuracy: 78.69%\n",
      "\n",
      "\n",
      "New best: 78.69%\n",
      "\n",
      "\n",
      "===================== RUN: 3/200 =====================\n",
      "\n",
      "# ------------------------------- #\n",
      "\n",
      "Test Accuracy: 68.31%\n",
      "\n",
      "===================== RUN: 4/200 =====================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 31\u001B[39m\n\u001B[32m     29\u001B[39m outputs = model(images)\n\u001B[32m     30\u001B[39m loss = criterion(outputs, labels)\n\u001B[32m---> \u001B[39m\u001B[32m31\u001B[39m \u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     32\u001B[39m optimizer.step()\n\u001B[32m     34\u001B[39m running_loss += loss.item()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:647\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    637\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    638\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    639\u001B[39m         Tensor.backward,\n\u001B[32m    640\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    645\u001B[39m         inputs=inputs,\n\u001B[32m    646\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m647\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mautograd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    648\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\n\u001B[32m    649\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    349\u001B[39m     retain_graph = create_graph\n\u001B[32m    351\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    352\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    353\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m354\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    356\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    357\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    358\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    359\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs_tuple\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    360\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    361\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    362\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\graph.py:829\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    827\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    828\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m829\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execution_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[32m    830\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    831\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    832\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    833\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
