{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-24T07:01:10.688151Z",
     "start_time": "2025-09-24T07:01:10.685650Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import kornia.augmentation as K\n",
    "from projects.VolcanoFinder.web.models import MyFirstCNN\n",
    "import math"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "7f32892949fe66c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T07:01:11.854573Z",
     "start_time": "2025-09-24T07:01:10.690665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cpu_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder(root='C:/Users/spec/Documents/programming/projects/VolcanoFinder/data/train', transform=cpu_transforms)\n",
    "val_dataset = ImageFolder(root='C:/Users/spec/Documents/programming/projects/VolcanoFinder/data/val', transform=cpu_transforms)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=12,\n",
    "    prefetch_factor=6,\n",
    "    persistent_workers=True,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=12,\n",
    "    prefetch_factor=6,\n",
    "    persistent_workers=True,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "gpu_augmentations = nn.Sequential(\n",
    "    K.Resize((128, 128)),\n",
    "    K.RandomHorizontalFlip(p=0.7),\n",
    "    K.RandomAffine(degrees=0, translate=(0.2, 0.2)),\n",
    "    K.Normalize(mean=torch.tensor([0.5, 0.5, 0.5], device=device),\n",
    "                std=torch.tensor([0.5, 0.5, 0.5], device=device))\n",
    ").to(device)\n",
    "\n",
    "# ------------------------------- #\n",
    "# Tried, but disadvantageous: RandRotation, RandGaussianNoise, ColorJitter, RandGauBlur, RandSolarize\n",
    "# ------------------------------- #\n",
    "\n",
    "model = MyFirstCNN().to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "\n",
    "scheduler =  torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.6, patience=3)\n",
    "\n",
    "# ------------------------------- #"
   ],
   "id": "82918d47816296de",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T07:01:20.925280Z",
     "start_time": "2025-09-24T07:01:11.858744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ------------------------------- #\n",
    "\n",
    "num_epochs: int = 10\n",
    "best_val_loss: float = math.inf\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    running_loss: float = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.float().unsqueeze(1).to(device, non_blocking=True)\n",
    "\n",
    "        images = gpu_augmentations(images)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "    # Validation Loop\n",
    "    model.eval()\n",
    "    val_correct: int = 0\n",
    "    val_total: int = 0\n",
    "    val_loss: float = 0.0\n",
    "    with torch.inference_mode(): # Faster than no_grad by a massive 2 seconds or ~3.076% (1m3s vs 1m5s)\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.float().unsqueeze(1).to(device, non_blocking=True)\n",
    "\n",
    "            outputs = model(images)\n",
    "            val_loss += criterion(outputs, labels.float()).item()\n",
    "\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_val_loss: float = val_loss / len(val_loader)\n",
    "    val_accuracy: float = 100 * val_correct / val_total\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), 'volcano_finder_myownc'\n",
    "                                       'nn_best.pth')\n",
    "        print(f\" ------------- Best model saved | Epoch: {epoch + 1}, Val loss: {avg_val_loss:.4f} ------------- \")\n",
    "\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "# ------------------------------- #"
   ],
   "id": "77d858704746c80b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training Loss: 0.8591\n",
      " ------------- Best model saved | Epoch: 1, Val loss: 0.6851 ------------- \n",
      "Validation Loss: 0.6851, Accuracy: 62.30%\n",
      "Epoch 2/10, Training Loss: 0.5289\n",
      "Validation Loss: 0.7022, Accuracy: 63.93%\n",
      "Epoch 3/10, Training Loss: 0.4471\n",
      " ------------- Best model saved | Epoch: 3, Val loss: 0.5919 ------------- \n",
      "Validation Loss: 0.5919, Accuracy: 72.95%\n",
      "Epoch 4/10, Training Loss: 0.4306\n",
      "Validation Loss: 0.6202, Accuracy: 65.30%\n",
      "Epoch 5/10, Training Loss: 0.3911\n",
      "Validation Loss: 0.6450, Accuracy: 56.56%\n",
      "Epoch 6/10, Training Loss: 0.4081\n",
      " ------------- Best model saved | Epoch: 6, Val loss: 0.5907 ------------- \n",
      "Validation Loss: 0.5907, Accuracy: 61.20%\n",
      "Epoch 7/10, Training Loss: 0.4062\n",
      " ------------- Best model saved | Epoch: 7, Val loss: 0.5255 ------------- \n",
      "Validation Loss: 0.5255, Accuracy: 80.05%\n",
      "Epoch 8/10, Training Loss: 0.3494\n",
      "Validation Loss: 0.5385, Accuracy: 76.78%\n",
      "Epoch 9/10, Training Loss: 0.3234\n",
      "Validation Loss: 0.6637, Accuracy: 61.20%\n",
      "Epoch 10/10, Training Loss: 0.3325\n",
      "Validation Loss: 0.6218, Accuracy: 59.29%\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T07:01:21.120997Z",
     "start_time": "2025-09-24T07:01:20.929311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ------------------------------- #\n",
    "\n",
    "test_data_path = 'C:/Users/spec/Documents/programming/projects/VolcanoFinder/data/test_images'\n",
    "\n",
    "# Create a dataset and DataLoader for the test set\n",
    "# Use the same transforms as the val set\n",
    "test_dataset = ImageFolder(root=test_data_path, transform=cpu_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "loaded_model = MyFirstCNN().to(device)\n",
    "\n",
    "loaded_model.load_state_dict(torch.load('volcano_finder_myowncnn_best.pth'))\n",
    "\n",
    "loaded_model.to(device)\n",
    "loaded_model.eval()\n",
    "\n",
    "print(\"Model loaded successfully.\")\n",
    "\n",
    "test_correct: int = 0\n",
    "test_total: int = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "        outputs = loaded_model(images)\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy: float = 100 * test_correct / test_total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# ------------------------------- #"
   ],
   "id": "451554018889913b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "Test Accuracy: 79.78%\n"
     ]
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
